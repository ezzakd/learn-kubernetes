## Opis
Instalujemy Kubernetes na systemie Red Hat Enterprise Linux 9 z wykorzystaniem:
- containerd
- flannel

## Przygotowanie systemu

Należy podjąć następujące kroki:
1. Aktualizacja systemu.
2. Selinux Permissive Mode
3. Załadowanie oraz konfiguracja wymaganych modułów jądra systemu.
4. Instalacja oraz konfiguracja containerd
5. Instalacja oraz konfiguracja Kubernetes

### Aktualizacja systemu

Aktualizujemy system, w przypadku aktualizacji kernela wymagany będzie reboot.

```
dnf update -y
dnf autoremove
reboot
```

### Selinux Permissive Mode
Przestawiamy Selinux w tryb Permissive zgodnie z dokumentacją:
```
sudo setenforce 0
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
```
>Setting SELinux in permissive mode by running setenforce 0 and sed ... effectively disables it. This is required to allow containers to access the host filesystem, which is needed by pod networks for example. You have to do this until SELinux support is improved in the kubelet.  
>źródło: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl

### Załadowanie oraz konfiguracja wymaganych modułów jądra systemu.

Ładujemy oraz konfigurujemy wymagane moduły. Uruchamiamy ponownie system, po uruchomieniu weryfikujemy czy zmiany zostały wprowadzone.

```
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

reboot

lsmod | egrep "br_netfilter|overlay"
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```

> źródło: https://kubernetes.io/docs/setup/production-environment/container-runtimes/

### Instalacja oraz konfiguracja containerd

Instalujemy repozytorium CentOS, ponieważ Docker zapewnia na ten moment jedynie paczki dla RHEL na architekturze s390x.

> We currently only provide packages for RHEL on s390x (IBM Z). Other architectures are not yet supported for RHEL, but you may be able to install the CentOS packages on RHEL. Refer to the Install Docker Engine on CentOS page for details.  
> źródło: https://docs.docker.com/engine/install/rhel/

Instalujemy containerd, generujemy domyślny plik konfiguracyjny oraz zmieniamy cgroup driver na systemd, poniżej wyjaśnienie.

```
dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
dnf install containerd.io
containerd config default > /etc/containerd/config.toml
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
systemctl enable containerd --now
```

> The Container runtimes page explains that the systemd driver is recommended for kubeadm based setups instead of the kubelet's default cgroupfs driver, because kubeadm manages the kubelet as a systemd service.  
> źródło: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/

### Instalacja oraz konfiguracja Kubernetes

Dodajemy repozytorium Kubernetes, instalujemy paczki. Poniższy przykład z dokumentacji Kubernetes uniemożliwia omyłkową aktualizację paczek kubelet, kubeadm, kubectl poprzez ich wykluczenie.

```
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

dnf install kubelet kubeadm kubectl --disableexcludes=kubernetes
```

Inicjalizujemy klaster Kubernetes:

```
systemctl enable kubelet.service --now

kubeadm init --cri-socket unix:///run/containerd/containerd.sock --pod-network-cidr=10.244.0.0/16
```

Po zakończeniu polecenia kubeadm init wyświetlone zostanie polecenie z tokenem (kubeadm join), które należy zapisać, będzie potrzebne do dołączania kolejnych serwerów do klastra Kubernetes.

Następnie kopiujemy konfigurację dla kubectl (zarządzanie klastrem):

```
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

Instalujemy Flannel jako pod network plugin, będzie on odpowiadał za przydzielanie podsieci oraz routing w naszym klastrze.

```
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
```

Możemy zweryfikować status instalacji za pomocą poleceń:
```
kubectl describe nodes
kubectl get nodes -o wide
kubectl get pods --all-namespaces -o wide
```